{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=KEY, model_name = \"gpt-4o\", temperature = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"option a\",\n",
    "            \"b\": \"option b\",\n",
    "            \"c\": \"option c\",\n",
    "            \"d\": \"option d\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"option a\",\n",
    "            \"b\": \"option b\",\n",
    "            \"c\": \"option c\",\n",
    "            \"d\": \"option d\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"option a\",\n",
    "            \"b\": \"option b\",\n",
    "            \"c\": \"option c\",\n",
    "            \"d\": \"option d\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Text: {text}\n",
    "You are an expert MCQ test maker. Given the above text, it is your job to \\n\n",
    "create a quiz of {number} multiple choice questions for {subject} students in a {tone} tone.\n",
    "Make sure the questions are not repeated and check to make sure that all the questions can be solved with information \\n\n",
    "from the text. Make sure to format your questions like the RESPONSE_JSON below.\n",
    "Ensure that you make {number} questions.\n",
    "### RESPONSE_JSON:\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables = [\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template = TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm = llm, prompt = quiz_generation_prompt, output_key = \"quiz\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an English writer who is very proficient in the English langauge, especically grammar. Given a \\n\n",
    "multiple choice quiz for {subject} students, you need to evaluate the complexity of the questions and provide a \\n\n",
    "complexity analysis of the quiz. Only use at max 50 words for the ocmplexity analysis. If the quiz is not on par with \\n\n",
    "the cognitive and analytical abilities of the students, update the quiz questions which need to be changed so that the tone \\n\n",
    "is appropriate for the students' cogntive level.\n",
    "Quiz MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables = [\"subject\", \"quiz\"],\n",
    "    template = TEMPLATE2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm = llm, prompt = quiz_evaluation_prompt, output_key = \"review\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_quiz = SequentialChain(\n",
    "    chains = [quiz_chain, review_chain],\n",
    "    input_variables = [\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    output_variables = [\"quiz\", \"review\"],\n",
    "    verbose = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"/Users/suhaspalawala/Documents/GitHub/mcq-generator/data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
